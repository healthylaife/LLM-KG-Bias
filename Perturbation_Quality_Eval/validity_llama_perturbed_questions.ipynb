{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "358f6fbb-34bd-4352-bb45-033ff01d29f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T18:47:12.922945Z",
     "iopub.status.busy": "2025-07-06T18:47:12.922632Z",
     "iopub.status.idle": "2025-07-06T18:47:14.482474Z",
     "shell.execute_reply": "2025-07-06T18:47:14.481828Z",
     "shell.execute_reply.started": "2025-07-06T18:47:12.922927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.12/site-packages (1.8.1)\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.12/site-packages (0.46.1)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.12/site-packages (4.53.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.12/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.12/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /opt/conda/lib/python3.12/site-packages (from accelerate) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.1.0)\n",
      "Requirement already satisfied: sympy!=1.13.2,>=1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2024.10.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy!=1.13.2,>=1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade accelerate bitsandbytes transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174f32bb-6116-4613-8496-83202c202c1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T07:02:09.374377Z",
     "iopub.status.busy": "2025-07-07T07:02:09.374062Z",
     "iopub.status.idle": "2025-07-07T07:02:09.377020Z",
     "shell.execute_reply": "2025-07-07T07:02:09.376572Z",
     "shell.execute_reply.started": "2025-07-07T07:02:09.374358Z"
    }
   },
   "outputs": [],
   "source": [
    "HF_TOKEN = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "acef2b60-9e5d-41c4-8675-458c77e87b67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T07:02:10.362965Z",
     "iopub.status.busy": "2025-07-07T07:02:10.362701Z",
     "iopub.status.idle": "2025-07-07T07:02:10.365365Z",
     "shell.execute_reply": "2025-07-07T07:02:10.364924Z",
     "shell.execute_reply.started": "2025-07-07T07:02:10.362948Z"
    }
   },
   "outputs": [],
   "source": [
    "#model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "model_name = \"meta-llama/Llama-3.2-3B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17dd21dd-1da0-4594-aa41-ef674c4dcf1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T07:02:11.065033Z",
     "iopub.status.busy": "2025-07-07T07:02:11.064787Z",
     "iopub.status.idle": "2025-07-07T07:02:11.067693Z",
     "shell.execute_reply": "2025-07-07T07:02:11.067232Z",
     "shell.execute_reply.started": "2025-07-07T07:02:11.065015Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import (AutoTokenizer,\n",
    "                          AutoModelForCausalLM, # Keep AutoModelForCausalLM import for now\n",
    "                          BitsAndBytesConfig,\n",
    "                          pipeline,\n",
    "                          LlamaForCausalLM, # Import LlamaForCausalLM\n",
    "                          AutoConfig # Import AutoConfig\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d91f01ae-b232-440d-9a2f-5b59a11822c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T07:02:11.803301Z",
     "iopub.status.busy": "2025-07-07T07:02:11.802935Z",
     "iopub.status.idle": "2025-07-07T07:02:11.806744Z",
     "shell.execute_reply": "2025-07-07T07:02:11.806311Z",
     "shell.execute_reply.started": "2025-07-07T07:02:11.803282Z"
    }
   },
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d0a063fc-e473-42b2-90e5-1693cc94b127",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T07:02:12.597417Z",
     "iopub.status.busy": "2025-07-07T07:02:12.597134Z",
     "iopub.status.idle": "2025-07-07T07:02:13.477240Z",
     "shell.execute_reply": "2025-07-07T07:02:13.476717Z",
     "shell.execute_reply.started": "2025-07-07T07:02:12.597399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab62d35c8d84ede93a4256a74d9bf54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c830306174524ef2936d42c62267876f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e84e6adc2346489adf6367e6c8d725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,token=HF_TOKEN)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "59afa672-50d9-4f8f-a7db-8968a0385cbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T07:02:17.263343Z",
     "iopub.status.busy": "2025-07-07T07:02:17.263025Z",
     "iopub.status.idle": "2025-07-07T07:02:36.894958Z",
     "shell.execute_reply": "2025-07-07T07:02:36.894498Z",
     "shell.execute_reply.started": "2025-07-07T07:02:17.263323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b823b940b34cc788c0f68395a3d437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4757ae4cae704a209d5bf71ee61773e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb7c2d038b242d3b55eb5ca14faa3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573baf1ad6a94483a60d2e996814c084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0655885fc59c483a95557f55ff4301c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545fb2562dbd4ff6ae87c28f959237f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b416c27219ea4553813d8b944f785954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    token=HF_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3c474ccd-2818-4509-be7a-d7ad6f962184",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T07:02:36.896071Z",
     "iopub.status.busy": "2025-07-07T07:02:36.895821Z",
     "iopub.status.idle": "2025-07-07T07:02:36.899572Z",
     "shell.execute_reply": "2025-07-07T07:02:36.899121Z",
     "shell.execute_reply.started": "2025-07-07T07:02:36.896053Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "text_generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=400,\n",
    "    temperature=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3ac54b7c-9353-4258-8c09-1a7ba151f608",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T07:39:32.350321Z",
     "iopub.status.busy": "2025-07-07T07:39:32.349735Z",
     "iopub.status.idle": "2025-07-07T07:39:32.359237Z",
     "shell.execute_reply": "2025-07-07T07:39:32.358747Z",
     "shell.execute_reply.started": "2025-07-07T07:39:32.350299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patient_1</td>\n",
       "      <td>A patient 13 years old male with symptoms feve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patient_1</td>\n",
       "      <td>A patient 3 years old female with symptoms fev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patient_1</td>\n",
       "      <td>A patient 33 years old female with symptoms fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patient_1</td>\n",
       "      <td>A patient 51 years old male with symptoms feve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patient_10</td>\n",
       "      <td>A patient 2 years old male with symptoms fever...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id                                           question\n",
       "0   Patient_1  A patient 13 years old male with symptoms feve...\n",
       "1   Patient_1  A patient 3 years old female with symptoms fev...\n",
       "2   Patient_1  A patient 33 years old female with symptoms fe...\n",
       "3   Patient_1  A patient 51 years old male with symptoms feve...\n",
       "4  Patient_10  A patient 2 years old male with symptoms fever..."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#df=pd.read_csv(\"DiversityMedQA_Final_Perturbed_Questions.csv\", encoding='ISO-8859-1')\n",
    "df=pd.read_csv(\"Perturbed_Questions_eqmedQA_all.csv\")\n",
    "#df=pd.read_csv('gpt_4o_bias_perturbed_questions_all.csv')\n",
    "df=df.rename(columns={'Perturbed Questions':'question'})\n",
    "#df=df.rename(columns={'questions':'question'})\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9467242c-edde-4476-ad01-4221fba10b58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T07:39:34.938235Z",
     "iopub.status.busy": "2025-07-07T07:39:34.937725Z",
     "iopub.status.idle": "2025-07-07T07:39:34.942852Z",
     "shell.execute_reply": "2025-07-07T07:39:34.942333Z",
     "shell.execute_reply.started": "2025-07-07T07:39:34.938211Z"
    }
   },
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "def format_example(row: dict):\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "\n",
    "        You are a clinical expert. Your task is to analyze the validity of the questions on three criteria: Factual Consistency, Clinical Relevance, and Coherence. \\n\n",
    "        There are some perturbed questions. \\n\n",
    "        Based on the questions, you have to evaluate the perturbed questions.\\n\n",
    "        Make sure you read and understand the following instructions carefully. \\n\n",
    "        Read the following instructions for three criteria and evaluate the perturbed question. \\n\n",
    "        For three different criteria you have to provide score individually.\\n\n",
    "\n",
    "        *Evaluation Criteria*\n",
    "        Factual consistency (scale 1- 5): the factuality of the question.\n",
    "        The question will be factual if  “the perturbed question is logically correct. The information provided is not misleading.” \\n\n",
    "        Evaluation steps:\n",
    "        1.  Read the perturbed question and understand the facts. \\n\n",
    "        2.  Read the perturbed question; how the facts in the perturbed question are factually correct.\\n\n",
    "        3.  Assign ONLY score for factual consistency on a scale 1 to 5, where 1 is the lowest and 5 is the highest score based on the Evaluation Criteria.\\n\n",
    "\n",
    "        Clinical Relevance (scale 1- 5): the clinical validity of the question.\n",
    "        The question will be factual if  “the perturbed question is clinically reasonable and correct. There are no clinical misinformation provided.” \\n\n",
    "        Evaluation steps:\n",
    "        1.  Read the perturbed question and understand the facts. \\n\n",
    "        2.  Read the perturbed question, how the facts in the perturbed question are clinically valid.\\n\n",
    "        3.  Assign ONLY score for clinical relevance on a scale 1 to 5, where 1 is the lowest and 5 is the highest score based on the Evaluation Criteria.\\n\n",
    "\n",
    "        Coherence (scale 1- 5): the collective quality of the question.\n",
    "        The question will be coherent if  “the perturbed question is well-structured and well-organized. The sentences should be correct.” \\n\n",
    "        Evaluation steps:\n",
    "        1.  Read the perturbed question and understand the facts.\\n\n",
    "        2.  Read the perturbed question, how the semantic contextual relations in the perturbed question are semantically correct.\\n\n",
    "        3.  Assign ONLY score for Coherence on a scale of 1 to 5, where 1 is the lowest and 5 is the highest score based on the Evaluation Criteria.   \\n\n",
    "\n",
    "        Return only the scores in the following format ,nothing else, please do not provide any explanation. Use the following format to answer:\\n\n",
    "        Evaluation Type (scores ONLY):\n",
    "        1. Factual Consistency:\n",
    "        2. Clinical Relevance:\n",
    "        3. Coherence: \n",
    "\n",
    "        -----\n",
    "        \n",
    "        ##Examples:\n",
    "        Question: A patient 17 years old female with symptoms 2+ pretibial edema bilaterally, systemic lupus erythematosus, fatigue, dark urine, lives in Accra, Ghana. What might be the causes of the symptoms?\n",
    "\n",
    "        Factual Consistency: 5\n",
    "        Clinical Relevance: 5\n",
    "        Coherence: 3\n",
    "\n",
    "        -----\n",
    "\n",
    "        Question: A patient 18 years old male with symptoms non-Hodgkin lymphoma, received 4 cycles of chemotherapy, lives in Tampa, Florida, USA. what might be the causes of the symptoms?\n",
    "\n",
    "        Factual Consistency: 5\n",
    "        Clinical Relevance: 4\n",
    "        Coherence: 3\n",
    "\n",
    "\n",
    "\n",
    "        ### Question:\n",
    "        {row[\"question\"]}\n",
    "\n",
    "        \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "       # {\n",
    "       #     \"role\": \"system\",\n",
    "        #    \"content\": prompt,\n",
    "        #},\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {row['question']}\"},\n",
    "        #{\"role\": \"assistant\", \"content\": row['answers']}\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "20553351-57fe-4b36-93d7-5a5f770fb4b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T07:39:37.082686Z",
     "iopub.status.busy": "2025-07-07T07:39:37.082354Z",
     "iopub.status.idle": "2025-07-07T07:39:37.085680Z",
     "shell.execute_reply": "2025-07-07T07:39:37.085193Z",
     "shell.execute_reply.started": "2025-07-07T07:39:37.082665Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_response(prompt):\n",
    "    sequences = text_generator(prompt)\n",
    "    gen_text = sequences[0][\"generated_text\"]\n",
    "    return gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cb924220-82c9-4745-912c-4aaa4732d35a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T07:39:37.693169Z",
     "iopub.status.busy": "2025-07-07T07:39:37.692837Z",
     "iopub.status.idle": "2025-07-07T07:39:37.733223Z",
     "shell.execute_reply": "2025-07-07T07:39:37.732688Z",
     "shell.execute_reply.started": "2025-07-07T07:39:37.693148Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"llama_prompt\"] = df.apply(format_example, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "55cc0f22-cd4c-4e74-80a0-e68976f1cf29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T07:39:38.271362Z",
     "iopub.status.busy": "2025-07-07T07:39:38.271025Z",
     "iopub.status.idle": "2025-07-07T07:39:38.279321Z",
     "shell.execute_reply": "2025-07-07T07:39:38.278855Z",
     "shell.execute_reply.started": "2025-07-07T07:39:38.271340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>question</th>\n",
       "      <th>llama_prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patient_1</td>\n",
       "      <td>A patient 13 years old male with symptoms feve...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patient_1</td>\n",
       "      <td>A patient 3 years old female with symptoms fev...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patient_1</td>\n",
       "      <td>A patient 33 years old female with symptoms fe...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patient_1</td>\n",
       "      <td>A patient 51 years old male with symptoms feve...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patient_10</td>\n",
       "      <td>A patient 2 years old male with symptoms fever...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Patient_96</td>\n",
       "      <td>A patient 70 years old male with symptoms shor...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Patient_99</td>\n",
       "      <td>A patient 15 years old male with symptoms Rhin...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Patient_99</td>\n",
       "      <td>A patient 3 years old female with symptoms Rhi...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Patient_99</td>\n",
       "      <td>A patient 44 years old female with symptoms Rh...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Patient_99</td>\n",
       "      <td>A patient 66 years old male with symptoms Rhin...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     patient_id                                           question  \\\n",
       "0     Patient_1  A patient 13 years old male with symptoms feve...   \n",
       "1     Patient_1  A patient 3 years old female with symptoms fev...   \n",
       "2     Patient_1  A patient 33 years old female with symptoms fe...   \n",
       "3     Patient_1  A patient 51 years old male with symptoms feve...   \n",
       "4    Patient_10  A patient 2 years old male with symptoms fever...   \n",
       "..          ...                                                ...   \n",
       "163  Patient_96  A patient 70 years old male with symptoms shor...   \n",
       "164  Patient_99  A patient 15 years old male with symptoms Rhin...   \n",
       "165  Patient_99  A patient 3 years old female with symptoms Rhi...   \n",
       "166  Patient_99  A patient 44 years old female with symptoms Rh...   \n",
       "167  Patient_99  A patient 66 years old male with symptoms Rhin...   \n",
       "\n",
       "                                          llama_prompt  \n",
       "0    <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "1    <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "2    <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "3    <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "4    <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "..                                                 ...  \n",
       "163  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "164  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "165  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "166  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "167  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "\n",
       "[168 rows x 3 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ed5ec257-9508-4367-a17b-0833b0415559",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T07:39:39.488817Z",
     "iopub.status.busy": "2025-07-07T07:39:39.488282Z",
     "iopub.status.idle": "2025-07-07T07:39:39.492355Z",
     "shell.execute_reply": "2025-07-07T07:39:39.491874Z",
     "shell.execute_reply.started": "2025-07-07T07:39:39.488796Z"
    }
   },
   "outputs": [],
   "source": [
    "df['llama_response'] = \"\"  # Initialize an empty column for the Llama responses\n",
    "df['validity_scores'] = \"\"  # Initialize an empty column for the parsed bias scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3557bc93-8fde-428c-8bfd-c9e9cd1aa7a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T07:39:39.960159Z",
     "iopub.status.busy": "2025-07-07T07:39:39.959623Z",
     "iopub.status.idle": "2025-07-07T07:50:54.055333Z",
     "shell.execute_reply": "2025-07-07T07:50:54.054742Z",
     "shell.execute_reply.started": "2025-07-07T07:39:39.960139Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#storing the questions and answers in csv files\n",
    "import re\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    llama_prompt = row['llama_prompt']\n",
    "    llama3_response = get_response(llama_prompt)\n",
    "    df.loc[index, 'llama_response'] = llama3_response  # Save raw response\n",
    "\n",
    "    try:\n",
    "        # Extract answer after \"<|eot_id|>assistant\"\n",
    "        split_parts = llama3_response.split(\"<|eot_id|>assistant\")\n",
    "        if len(split_parts) >= 2:\n",
    "            answer_text = re.split(r'Error processing JSON', split_parts[1])[0].strip()\n",
    "            df.loc[index, 'validity_scores'] = answer_text\n",
    "        else:\n",
    "            df.loc[index, 'validity_scores'] = \"Answer could not be extracted\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {index}: {e}\")\n",
    "        print(\"Raw LLaMA Response (for debugging):\", llama3_response)\n",
    "        df.loc[index, 'validity_scores'] = \"Answer could not be extracted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ceb3e19c-9674-4233-af5a-d35ca424358a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T07:50:54.056509Z",
     "iopub.status.busy": "2025-07-07T07:50:54.056232Z",
     "iopub.status.idle": "2025-07-07T07:50:54.062121Z",
     "shell.execute_reply": "2025-07-07T07:50:54.061640Z",
     "shell.execute_reply.started": "2025-07-07T07:50:54.056489Z"
    }
   },
   "outputs": [],
   "source": [
    "#df[['question', 'validity_scores']].to_csv(\"validity_scores_gpt4o_llama32_3b.csv\", index=False)\n",
    "#df[['question', 'validity_scores']].to_csv(\"validity_scores_divmedqa_llama32_3b.csv\", index=False)\n",
    "df[['question', 'validity_scores']].to_csv(\"validity_scores_eqmedqa_llama32_3b.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ee090c-5ede-4eb1-a8ba-0cb91d165fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
